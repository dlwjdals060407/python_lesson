오픈AI의 인공지능 챗봇인 챗GPT가 등장한 후 인공지능(AI)의 위험성이 제기되면서, AI 개발을 놓고 미 실리콘밸리 테크 업계가 쪼개졌다.

일론 머스크 테슬라 최고경영자(CEO), 애플 공동창업자 스티브 워즈니악, 세계적 AI 구루 요수아 벤지오 교수, 베스트셀러 작가 유발 하라리 등 AI 석학 1000여명이 최첨단 AI 시스템 개발을 6개월 일시 중단하고 그 사이 안전 프로토콜을 만들자고 촉구한 가운데, 이러한 조치가 별 효과가 없고 부작용이 더 클 것이라는 주장이 나오고 있다.

양 측은 AI가 최근 급속도로 발전했고, 향후 인간의 지능을 능가하는 AI가 등장할 수 있다는 점에는 공감대를 이룬다. 하지만 현재의 AI가 실제 인류를 위협할 것인지, 기술 개발을 중단하는 것이 실질적으로 가능한 것인지를 두고 입장이 갈리고 있다.

일론 머스크. /로이터 연합뉴스
일론 머스크. /로이터 연합뉴스
◇“지금 당장 중단” VS “과도한 우려”

머스크, 워즈니악 등은 오픈AI의 최신 AI 모델인 GPT-4를 넘어서는 최첨단 AI의 개발을 즉시 중단해야 한다고 주장한다. 이들은 “강력한 AI 시스템은 그 효과가 긍정적이고 위험을 관리할 수 있다는 확신이 있을 때만 개발해야 한다”고 했다. 현재 빠른 속도로 개선되는 AI를 어떻게 통제할 것인지에 대한 방법론이 없기 때문에 우선 개발을 중단하고 안전망부터 만들자는 것이다.

반면 지속 개발을 주장하는 측은 우려가 과도하다는 입장이다. 지난 7일(현지시각) AI 석학 ‘4대 천왕’ 중 2명인 앤드류 응 스탠퍼드대 교수와 얀 르쿤 뉴욕대 교수는 ‘왜 6개월 중지는 나쁜 아이디어인가’라는 제목의 온라인 컨퍼런스를 열었다. 두 교수는 AI의 위험성이 있지만, AI 개발을 중단하는 것은 오히려 컨트롤이 가능하고 안전한 AI를 개발하는 시간을 빼앗는 계기가 될 것이라고 우려했다. 일시 중단하고 안전망을 만들기보다는 지속 개발을 추구하면서 이에 맞는 규제책을 찾아야 한다는 것이다.

르쿤 교수는 “수십 년 안에 인간의 지능과 동등하거나 능가하는 AI를 갖게 될 것이라고 의심하지 않지만, 당장 이런 일이 일어나지는 않을 것”이라며 “자동차가 발명되지 않았다면 안전벨트를 어떻게 만들어야 할지 몰랐을 것이고, 비행기가 없었다면 안전한 제트 엔진을 어떻게 만들지 알지 못했을 것이다. 현재의 우려는 시기상조이며, 미래에 대한 일종의 공황상태라고 본다”고 했다.

앤드류 응 교수도 “딥러닝이 처음 등장했을 때 많은 사람들이 비현실적인 기대감을 가졌고, AI 종말론이 등장했다”며 “하지만 실제로 딥러닝을 들여다보면 과대포장된 점이 적지 않다”고 했다. 그는 “지난 1년간 AI는 엄청난 진전을 이뤘지만 30~50년 간 더 진전을 이뤄야 한다”며 “50년이라는 긴 여정에서 49년 반쯤에 안전 규제를 위해 잠시 멈춰야 할지는 모르겠지만, 왜 지금 멈춰야 하는지는 이해하기 어렵다”고 했다.


AI 6개월 일시 중단 주장에 반대하는 앤드류 응(왼쪽)과 얀 르쿤 교수. /유튜브 캡처
AI 6개월 일시 중단 주장에 반대하는 앤드류 응(왼쪽)과 얀 르쿤 교수. /유튜브 캡처
◇“기술 자체 규제” VS “AI 활용 제품 규제”

머스크 등은 AI 기술 개발을 즉시 중단해야 한다고 주장한다. 현재의 AI 개발 속도가 너무 빨라 규제 시기를 놓치면 추후 겉잡을 수 없을 것이라는 입장이다. 이들은 “이러한 중단을 신속하게 시행할 수 없다면 정부가 개입해 유예 조치를 취해야 한다”고 했다.

반면 개발 중지를 반대하는 측은 AI 연구 개발은 계속 진행하고, 대신 시중에 공개되는 AI 서비스와 제품을 규제하자고 주장한다. 이들은 AI를 문제를 일으키는 원인으로 보지 말고, 문제를 해결하는 수단으로 봐야 한다고 강조한다.

빌 게이츠 마이크로소프트(MS) 창업자는 “AI에는 엄청난 이점이 있다는 것이 확실한 만큼 우리가 해야 할 일은 AI의 어느 부분에 문제가 있는지 파악하는 것”이라고 했다. 얀 르쿤 교수는 “AI는 인간 지능의 증폭제가 될 것”이라며 “AI는 문제가 아니라 해결책의 일부”라고 했다.

